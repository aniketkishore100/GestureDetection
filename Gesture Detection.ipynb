{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen  = ImageDataGenerator(\n",
    "        rotation_range=40, #rotates images in a random manner btw 0 to 40 degree\n",
    "        rescale=1./255, #normalizes all images to a scale btw 0 to 1\n",
    "        shear_range=0.2, #stretches image in a shear manner \n",
    "        zoom_range=0.2, #zooms images in a random order\n",
    "        horizontal_flip=True,#flips the images\n",
    "        fill_mode='nearest') # after rotation the images may produce black spots\n",
    "train  = training_datagen.flow_from_directory('dataSet/train' , \n",
    "                                              target_size = (64,64),# the size in which images will be resized\n",
    "                                              batch_size=32, # no. of images in a batch\n",
    "                                              class_mode = 'binary')# as we are using 1D binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test = testing_datagen.flow_from_directory('dataSet/test',\n",
    "                                          target_size = (64,64), \n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True,\n",
    "                                          class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers import Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()#model type which allows us to build models in layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))#1st Convolutional layer with relu as a activation fn and 64 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(2,2))#1st maxPool layer with size of 2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))#2nd Conv layer with nodes reduced to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(2,2))#2nd maxPool layer with size of 2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())#provides connection btw dense and Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=2, activation='softmax'))#output layer with 2 nodes denoting 2 gestures used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "#here we have defined the optimizer and the way how the model will calculate the loss and the metrics to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 38s 600ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 1.7881e-08 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 39s 625ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 6.8932e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 36s 579ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 7.8588e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 37s 584ms/step - loss: 0.0125 - accuracy: 0.9950 - val_loss: 3.6359e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 36s 579ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 1.1802e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7febe03261f0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train, validation_data = test, epochs = 5)\n",
    "#we fit the train data and check for the test data with epochs set to 5 as the no. of times the model will run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataSet/test_image.png', target_size = (64, 64))#loading the single test image\n",
    "test_image = image.img_to_array(test_image)#converting the image into an array\n",
    "test_image = np.expand_dims(test_image, axis = 0)#changes the shape of the array do as to fit the model\n",
    "result = model.predict(test_image)#testing the image onto our model\n",
    "train.class_indices\n",
    "if result[0][0] == 1:\n",
    "    pred= 'fist'#providing the classes for the output\n",
    "elif result[0][1]==1:\n",
    "    pred=\"thumb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thumb\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
